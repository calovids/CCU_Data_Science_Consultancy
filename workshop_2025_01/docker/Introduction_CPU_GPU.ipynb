{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matrix_multiply(A, B):\n",
    "    n = len(A)\n",
    "    p = len(B[0])\n",
    "    m = len(B)\n",
    "    result = [[0] * p for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            for k in range(m):\n",
    "                result[i][j] += A[i][k] * B[k][j]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matrix_multiply_np(A, B,Reps):\n",
    "    C=np.dot(A, B)\n",
    "    for i in range(Reps):\n",
    "        C=np.dot(A, C)\n",
    "    return C    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matrix_multiply_torch(A, B, Reps):\n",
    "    # Check if CUDA (GPU support) is available\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    A_torch = torch.tensor(A, dtype=torch.float64).to(device)\n",
    "    B_torch = torch.tensor(B, dtype=torch.float64).to(device)\n",
    "    C_torch = torch.matmul(A_torch, B_torch)  # Perform the first multiplication on the GPU\n",
    "\n",
    "    for i in range(Reps):  # Subtract 1 because the first multiplication is already done\n",
    "        C_torch = torch.matmul(A_torch, C_torch)  # Further multiplications on the GPU\n",
    "\n",
    "    C = C_torch.cpu().numpy()  # Only move the final result to CPU and convert to NumPy\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is: cuda\n",
      "Plain Python time: 34.920814514160156\n",
      "NumPy time: 0.16881370544433594\n",
      "PyTorch (GPU) time: 0.35549473762512207\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Generate random matrices\n",
    "n = 512\n",
    "Reps=20\n",
    "A = np.random.rand(n, n).astype(np.float64)\n",
    "B = np.random.rand(n, n).astype(np.float64)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"device is:\",device)\n",
    "\n",
    "#Measure performance of plain Python\n",
    "start_time = time.time()\n",
    "result_python = matrix_multiply(A.tolist(), B.tolist())\n",
    "print(\"Plain Python time:\", time.time() - start_time)\n",
    "\n",
    "# Measure performance of NumPy\n",
    "start_time = time.time()\n",
    "result_np = matrix_multiply_np(A, B,Reps)\n",
    "print(\"NumPy time:\", time.time() - start_time)\n",
    "\n",
    "# Measure performance of PyTorch with GPU\n",
    "start_time = time.time()\n",
    "result_torch = matrix_multiply_torch(A, B,Reps)\n",
    "print(\"PyTorch (GPU) time:\", time.time() - start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using timeit to properly benchmark functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is: cuda\n",
      "numpy  10 0.17949371734994202\n",
      "Torch  10 0.029094928074846392\n",
      "numpy  20 0.16577136422511102\n",
      "Torch  20 0.045954912174966014\n",
      "numpy  30 0.2015374072751001\n",
      "Torch  30 0.06438540879989887\n",
      "numpy  40 0.5141295618001095\n",
      "Torch  40 0.08124777332486702\n",
      "numpy  50 0.36966224070001774\n",
      "Torch  50 0.09956418292495073\n",
      "numpy  60 0.5264189494249877\n",
      "Torch  60 0.11781185972504318\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use the 'Agg' backend for file creation\n",
    "import torch\n",
    "import timeit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"device is:\",device)\n",
    "\n",
    "n = 512\n",
    "A = np.random.rand(n, n).astype(np.float64)\n",
    "B = np.random.rand(n, n).astype(np.float64)\n",
    "reps_range = range(10, 61, 10)\n",
    "numpy_times = []\n",
    "torch_times = []\n",
    "number = 40\n",
    "\n",
    "for Reps in reps_range:\n",
    "    # Time NumPy\n",
    "    numpy_time = timeit.timeit('matrix_multiply_np(A, B, Reps)', globals=globals(), number=number)/number\n",
    "    print('numpy ',Reps, numpy_time)\n",
    "    numpy_times.append(numpy_time)\n",
    "\n",
    "    # Time PyTorch\n",
    "    torch_time = timeit.timeit('matrix_multiply_torch(A, B,  Reps)', globals=globals(), number=number)/number\n",
    "    print('Torch ',Reps, torch_time)\n",
    "    torch_times.append(torch_time)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(reps_range, numpy_times, label='NumPy', marker='o')\n",
    "plt.plot(reps_range, torch_times, label='PyTorch', marker='x')\n",
    "plt.xlabel('Number of Repetitions (Reps)')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Performance Comparison: NumPy vs. PyTorch GPU')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.draw()\n",
    "plt.savefig('reps_docker.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using more GPU intensive calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 256x256\n",
      "NumPy Duration: 0.007596492767333984\n",
      "Torch GPU Duration: 0.0424041748046875\n",
      "Difference: 1.952616858602596e-05 \n",
      "\n",
      "Size: 512x512\n",
      "NumPy Duration: 0.022054433822631836\n",
      "Torch GPU Duration: 0.05364179611206055\n",
      "Difference: 8.04747834877162e-05 \n",
      "\n",
      "Size: 1024x1024\n",
      "NumPy Duration: 0.054381608963012695\n",
      "Torch GPU Duration: 0.07471203804016113\n",
      "Difference: 0.00020822434919409716 \n",
      "\n",
      "Size: 2048x2048\n",
      "NumPy Duration: 0.5141119956970215\n",
      "Torch GPU Duration: 0.14284086227416992\n",
      "Difference: 0.0006645154892339633 \n",
      "\n",
      "Size: 4096x4096\n",
      "NumPy Duration: 3.4417924880981445\n",
      "Torch GPU Duration: 0.34295654296875\n",
      "Difference: 0.004599885652623925 \n",
      "\n",
      "Size: 8192x8192\n",
      "NumPy Duration: 15.62960433959961\n",
      "Torch GPU Duration: 0.9709539413452148\n",
      "Difference: 0.014186640691605135 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def multiply_numpy(A, B):\n",
    "    return np.dot(A, B)\n",
    "\n",
    "def multiply_torch(A, B):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    A_torch = torch.tensor(A, dtype=torch.float32).to(device)\n",
    "    B_torch = torch.tensor(B, dtype=torch.float32).to(device)\n",
    "    return torch.matmul(A_torch, B_torch).cpu().numpy()\n",
    "\n",
    "# Sizes of the matrices to test\n",
    "sizes = [256, 512, 2**10, 2**11, 2**12,2**13]\n",
    "numpy_times = []\n",
    "torch_times = []\n",
    "\n",
    "\n",
    "for size in sizes:\n",
    "    A = np.random.rand(size, size).astype(np.float64)\n",
    "    B = np.random.rand(size, size).astype(np.float64)\n",
    "\n",
    "    # Time NumPy\n",
    "    start_time = time.time()\n",
    "    Cnp=multiply_numpy(A, B)\n",
    "    numpy_duration = time.time() - start_time\n",
    "    numpy_times.append(numpy_duration)\n",
    "\n",
    "    # Time PyTorch with GPU\n",
    "    start_time = time.time()\n",
    "    Ctorch=multiply_torch(A, B)\n",
    "    torch_duration = time.time() - start_time\n",
    "    torch_times.append(torch_duration)\n",
    "\n",
    "    print(f\"Size: {size}x{size}\")\n",
    "    print(\"NumPy Duration:\", numpy_duration)\n",
    "    print(\"Torch GPU Duration:\", torch_duration)\n",
    "    print(\"Difference:\",np.max(np.abs(Cnp-Ctorch)),'\\n')    \n",
    "    \n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(sizes, numpy_times, label='NumPy', marker='o')\n",
    "plt.plot(sizes, torch_times, label='PyTorch GPU', marker='x')\n",
    "plt.xlabel('Matrix Size')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Performance Comparison: NumPy vs. PyTorch GPU')\n",
    "plt.yscale('log')  # Set the y-axis to logarithmic scale\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\")  # Enable grid for major and minor ticks\n",
    "plt.draw()\n",
    "plt.savefig('sizes_docker.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different GPU optimized functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Duration: 1.2434653197000443\n",
      "Torch GPU Duration: 0.705101901099988\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import timeit\n",
    "\n",
    "# Example image loading and conversion to numpy\n",
    "image = Image.open('Kinkade.jpg').convert('RGB')  # Ensure image is in RGB\n",
    "image_np = np.array(image).astype(np.float32)  # Convert to float for better handling in PyTorch\n",
    "image_torch = torch.tensor(image_np.transpose(2, 0, 1)).unsqueeze(0).to('cuda')  # Convert to Tensor and move to GPU\n",
    "\n",
    "# Define the target size as a tuple (width, height)\n",
    "size = (512*15, 512*15)  # Define the size as a tuple\n",
    "\n",
    "def numpy_resize(image_np, size):\n",
    "    return np.array(Image.fromarray(image_np.astype(np.uint8)).resize(size))\n",
    "\n",
    "def torch_resize(image_torch, size):\n",
    "    # size needs to be (height, width) for PyTorch, reverse the tuple\n",
    "    torch_size = (size[1], size[0])\n",
    "    return torch.nn.functional.interpolate(image_torch, size=torch_size, mode='bilinear', align_corners=False).cpu()\n",
    "\n",
    "# Timing the functions using timeit\n",
    "number = 10  # Number of iterations for timing\n",
    "\n",
    "# Time NumPy\n",
    "numpy_time = timeit.timeit('numpy_resize(image_np, size)', globals=globals(), number=number) / number\n",
    "\n",
    "# Time PyTorch\n",
    "torch_time = timeit.timeit('torch_resize(image_torch, size)', globals=globals(), number=number) / number\n",
    "\n",
    "print(\"NumPy Duration:\", numpy_time)\n",
    "print(\"Torch GPU Duration:\", torch_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions not optimized for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy time: 0.17585229750038706\n",
      "Torch time: 0.5166345161000209\n"
     ]
    }
   ],
   "source": [
    "# Creating a large array and summing it\n",
    "import timeit\n",
    "import numpy as np\n",
    "import torch\n",
    "large_data = np.random.rand(10**8)  # 10 million elements\n",
    "\n",
    "\n",
    "def sum_numpy(data):\n",
    "    return np.sum(data)\n",
    "\n",
    "def sum_torch(data):\n",
    "    tensor = torch.tensor(data).cuda()\n",
    "    return torch.sum(tensor).cpu()\n",
    "\n",
    "number=10\n",
    "# Timing the sum operations\n",
    "numpy_time = timeit.timeit('sum_numpy(large_data)', globals=globals(), number=number) / number\n",
    "\n",
    "\n",
    "torch_time = timeit.timeit('sum_torch(large_data)', globals=globals(), number=number) / number\n",
    "\n",
    "\n",
    "print(\"NumPy time:\", numpy_time)\n",
    "print(\"Torch time:\", torch_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
